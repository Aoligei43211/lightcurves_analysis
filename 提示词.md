## 1. 文件组织结构优化

### 实施步骤
- **扫描与创建**：遍历`data/HATP7b/`目录，为每个`.fits`文件创建同名文件夹（去除扩展名）
  - 示例：`1_tess2019198215352-s0014-0000000424865156-0150-s_lc/`
- **文件迁移**：将原始`.fits`文件移动到对应专属文件夹
- **输出目录规范**：
  - 单文件处理输出：保存在专属文件夹内的`outputs/`子目录
  - 多文件整合输出：保存在`data/HATP7b/shared_outputs/`共享目录
- **目录结构示例**：
```
data/HATP7b/
├── 1_tess2019198215352-s0014-0000000424865156-0150-s_lc/
│   ├── 1_tess2019198215352-s0014-0000000424865156-0150-s_lc.fits
│   └── outputs/
│       ├── processed_data.h5
│       └── period_analysis.json
├── 2_tess2019226182529-s0015-0000000424865156-0151-s_lc/
│   └── ...
└── shared_outputs/
    ├── combined_analysis.h5
    └── ...
```

### 技术实施说明
- 使用`os`和`shutil`库实现自动化文件迁移
- 创建目录管理类`DirectoryManager`，提供路径解析方法
- 在`data_processing_single.py`、`data_processing.py`中更新输出路径逻辑
- 实现配置文件读取机制，支持从配置文件获取需要数据的地址
- 在`config_manager.py`中实现依赖注入容器，管理算法实例的生命周期
- 使用`h5py`库实现分析结果的智能缓存和复用机制

## 2. 三层架构体系重构

### 架构定义
- **提取与预处理层 (Data Layer)** 
  - 模块：`data_processing.py`, `data_processing_sigle.py`, `读取_标签名_HDU.py`, `天文文件提取.py`
  - 职责：FITS文件I/O、数据完整性校验、存储管理
  - 接口：`read_fits()`, `validate_data()`, `get_data_path()`

- **处理层 (Processing Layer)** 
  - 模块： `lightcurves_noise_draw.py`, `lightcurve_period.py`, 
  - 职责：数据清洗、降噪算法、周期计算核心逻辑
  - 接口：`preprocess()`, `denoise()`, `calculate_period()`
  - 新增配置模块：`config_manager.py`，负责从配置文件读取路径和参数，实现依赖注入机制，支持通过配置动态选择分析算法和参数

- **应用层 (Application Layer)** 
  - 模块：`light_curve_draw_sigle.py`, `lightcurve_period_draw.py`, `arror-period_draw.py`
  - 职责：图表生成、深度分析、用户交互、
  - 接口：优化现有可视化函数，提供一致的交互体验

### 实施步骤
1. **模块组织**：
   - 按三层架构重新组织现有文件，不创建新文件，添加层级标记和接口规范文档
   - 在现有模块中定义标准接口抽象基类，或创建interfaces.py文件（如必要）
2. **依赖更新**：
   - 更新模块间导入语句，使用相对导入确保跨层调用
   - 在config_manager.py中实现配置读取和依赖注入功能
3. **接口优化**：
   - 在保留现有功能基础上优化接口一致性
   - 统一各层数据传递格式，确保数据流畅通

### 操作规范
- 数据层返回标准化的`DataContainer`对象
- 处理层实现纯函数，通过依赖注入机制动态选择算法
- 应用层通过回调机制处理用户交互
- 数据预处理（data_processing或single）模块必须从配置文件读取地址信息，不再硬编码文件路径
- 所有分析中间结果和最终数据必须存储到HDF5文件，避免重复计算

### 依赖注入机制实施
- **配置驱动**：通过`config.json`定义分析流程、算法选择和参数
- **动态加载**：使用工厂模式根据配置实例化对应的处理模块
- **结果缓存**：对相同的输入数据和参数组合，直接从HDF5存储读取分析结果
- **扩展接口**：新增算法只需实现标准接口并在配置中注册即可使用
- **模块集成**：config_manager.py通过依赖注入容器与现有处理模块（如period_calculator.py、lightcurves_noise_draw.py）集成，动态管理算法实例的生命周期和参数传递
- **配置验证**：实现配置文件的完整性校验和参数有效性验证，确保依赖注入安全可靠
- **错误处理**：在依赖注入过程中添加异常捕获和回退机制，防止配置错误导致系统崩溃

## 3. 结构化日志与数据流可视化

### 日志系统实施
- **配置格式**：
```python
LOG_FORMAT = '%(asctime)s - %(levelname)s - %(module)s - %(message)s - params: %(params)s'
```
- **日志级别**：DEBUG（详细处理流程）、INFO（关键操作）、ERROR（异常情况）
- **实施步骤**：
  1. 在各模块初始化时配置logger
  2. 在关键函数入口/出口添加日志记录
  3. 使用JSON格式记录结构化数据

### 数据流转示意图规范
- **工具要求**：使用draw.io或Lucidchart
- **图示要素**：
  - 模块节点标注输入/输出数据类型
  - 数据流箭头标注传输格式（如FITS→NumPy→HDF5）
  - 关键接口标注方法签名和返回类型
- **维护要求**：架构变更时同步更新示意图

## 4. HDF5数据存储标准

### 文件结构规范
```
/HATP7b/ (星体大组)
  ├── 1_tess2019198215352-s0014-0000000424865156-0150-s_lc/ (子文件组)
  │   ├── attributes/ (属性组)
  │   │   ├── source_file: str
  │   │   ├── processing_date: str
  │   │   └── algorithm_params: dict
  │   ├── preprocessed/ (数据集)
  │   │   ├── time: dataset
  │   │   ├── flux: dataset
  │   │   └── attributes: {unit: 'e-/s', normalized: True}
  │   └── processed/ (数据集)
  │       ├── denoised_flux: dataset
  │       └── periodogram: dataset
  ├── 2_tess2019226182529-s0015-0000000424865156-0151-s_lc/ (子文件组)
  │   └── ... 类似结构
  └── comprehensive/ (综合组)
      ├── attributes/ (属性组)
      │   ├── combined_source: list
      │   ├── processing_date: str
      │   └── algorithm_params: dict
      ├── combined_data/ (数据集)
      │   ├── time: dataset
      │   ├── flux: dataset
      │   └── attributes: {unit: 'e-/s', normalized: True}
      └── analysis_results/ (数据集)
          ├── best_period: dataset
          └── periodogram: dataset
```


### 技术实施
- 使用`h5py`库实现HDF5读写
- 实现`HDF5Manager`类封装存储操作，支持星体大组、子文件组和综合组的多层次管理
- 压缩策略：对大型数据集启用gzip压缩（compression='gzip'）
- 数据完整性：为每个数据集添加MD5校验和属性

### 操作规范
- 数据集命名采用蛇形命名法（snake_case）
- 属性记录必须包含数据来源、处理历史和校验信息
- 版本控制通过HDF5属性`format_version`管理
- 存储分析中间数据和最终结果，避免重复计算，节省计算资源
- 星体大组按观测文件组织，综合组用于存储合并分析结果

## 优先级实施计划
1. **立即执行**：文件组织结构重构、HDF5存储基础实现
2. **一周内完成**：三层架构核心模块拆分、日志系统集成
3. **两周内完善**：完整测试覆盖、数据流示意图绘制、性能优化

此方案确保系统具备高度可维护性，未来新增数据处理算法或数据源时，只需实现标准接口并更新数据流示意图即可快速集成。
        